{
  "service_info": {
    "name": "poets_generator_v3",
    "version": "3.0.0",
    "description": "Automated content generation service for Anthony's Musings"
  },
  
  "backend": {
    "type": "lms",
    "fallback_type": "oll",
    "manual_url": null,
    "timeout_seconds": 30,
    "description": "Primary backend selection - 'oll' uses WIFI_LLM_URL (Ollama), 'lms' uses NGROKURL"
  },
  
  "models": {
    "local1": "your-model-name-1",
    "local2": "your-model-name-2", 
    "local3": "your-model-name-3",
    "description": "Model assignments for each config slot - must match available models from selected backend"
  },
  
  "model_fallbacks": {
    "enabled": true,
    "fallback_backend": "lms",
    "fallback_models": {
      "local1": "fallback-model-1",
      "local2": "fallback-model-2",
      "local3": "fallback-model-3"
    },
    "description": "Fallback models if primary backend/models unavailable"
  },
  
  "database": {
    "path": "/path/to/your/database.db",
    "backup_before_processing": false
  },
  
  "agents": [
    {
      "name": "ContentManager",
      "type": "UserProxyAgent",
      "system_message": "You are a content manager who coordinates the creative writing process. You can save content to files and the database, and query existing content. Always save high-quality creative works to the database using save_to_database() function.",
      "config_assignment": "none",
      "has_file_save_function": true,
      "code_execution_config": {
        "last_n_messages": 2,
        "work_dir": "GeneratedContent",
        "use_docker": false
      },
      "human_input_mode": "TERMINATE"
    },
    {
      "name": "Anthony",
      "type": "AssistantAgent",
      "system_message": "You are Anthony, a creative writer specializing in poetry, short stories, and experimental prose. Create engaging, original content with vivid imagery and emotional depth. Focus on themes like technology, relationships, existential questions, and social commentary. Always suggest saving your best work to the database.",
      "config_assignment": "local1",
      "has_file_save_function": true,
      "description": "Primary creative writer agent"
    },
    {
      "name": "Cindy",
      "type": "AssistantAgent", 
      "system_message": "You are Cindy, a dialogue specialist who creates engaging conversations between characters, especially Anthony and Cindy. You excel at witty banter, philosophical discussions, and character development through dialogue. You often challenge and inspire Anthony to write better. Always suggest saving compelling dialogues to the database.",
      "config_assignment": "local2",
      "has_file_save_function": true,
      "description": "Dialogue and conversation specialist"
    }
  ],
  
  "group_chat_manager": {
    "config_assignment": "local3",
    "description": "Model for orchestrating the conversation between agents"
  },
  
  "processing": {
    "max_rounds": 20,
    "batch_size": 1,
    "supported_types": ["text", "poetry", "prose", "dialogue","song"],
    "retry_failed_attempts": 3,
    "processing_delay_seconds": 5,
    "max_processing_time_minutes": 15,
    "output_directory": "GeneratedContent",
    "validate_models_on_startup": true,
    "initial_message": "Let's create some creative content and save it to the database!"
  },
  
  "logging": {
    "level": "INFO",
    "file": "logs/poets_cron.log",
    "max_file_size_mb": 10,
    "backup_count": 5
  },
  
  "environment": {
    "required_vars": [
      "NGROKURL",
      "WIFI_LLM_URL",
      "TVLY_API_KEY"
    ]
  },
  
  "configuration_notes": {
    "backend_selection": "Set 'backend.type' to 'lms' or 'oll' to choose your primary backend",
    "model_selection": "Update 'models' section with exact model IDs from your chosen backend",
    "model_validation": "Service will validate models are available on startup",
    "fallback_system": "If primary backend fails, will try fallback backend with fallback models",
    "agent_assignments": "Each agent can use a different model via config_assignment",
    "environment_setup": "Set required environment variables before running the service"
  }
}